# -*- coding: utf-8 -*-
"""ResNet-152.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SuT2bNAVaEVld1iBr-mneiFeH8aCeObF
"""

import numpy as np
import torchvision.models as models
from PIL import Image
import os
import cv2 as cv
from sklearn import preprocessing
from sklearn.model_selection import train_test_split

from google.colab import drive
drive.mount('/content/drive')

# read image and set the x and y axis to be equal; then resize the image to "dim"
def load_images_from_folder(folder):
    images = []
    labels = []
    dim = (200,200)
    for filename in os.listdir(folder):
        img = cv.imread(os.path.join(folder,filename))
        if img is None:
          continue
        resized_img = cv.copyMakeBorder(img,80,80,0,0,cv.BORDER_CONSTANT,value=[255,255,255])
        lbl = filename[3:6]
        final_img = cv.resize(resized_img,dim,interpolation=cv.INTER_AREA)
        
        if final_img is not None:
            if lbl is not None:
                images.append(final_img)
                labels.append(lbl)
    
    return images, labels

folder = "/content/drive/MyDrive/new_image"
Imgs,lbls = load_images_from_folder(folder)

# print(Imgs[0].ndim)

label_encoder = preprocessing.LabelEncoder() #one-hot encoding
Y = label_encoder.fit_transform(lbls)

X_train, X_test, Y_train, Y_test = train_test_split(Imgs, Y, test_size=0.2, random_state=10)

from collections import Counter
print(len(Counter(Y).keys()))
print(X_train[0].ndim)

model = models.resnet152(pretrained=False)

import torchvision.datasets as datasets
import torchvision.transforms as transforms

batch_size = 16
learning_rate = 0.02
epoch = 100

transform = transforms.Compose([transforms.ToTensor(),
                              transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])])

import os
import torch
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt

class LetterDataset(Dataset):

    def __init__(self, imgs, labels, transform=None):
        #self.root = root
        self.imgs = imgs
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, index):
        # image_name = os.path.join(self.image_dir, self.image_files[index])  
        image = self.imgs[index]
        label = self.labels[index]
        if self.transform:
            image = self.transform(image)
        return (image, label)

X_train = np.array(X_train, dtype=np.uint8)
trainData = LetterDataset(X_train,Y_train,transform)
testData = LetterDataset(X_test,Y_test,transform)

X_train[0].shape

trainLoader = torch.utils.data.DataLoader(dataset=trainData, batch_size=batch_size, shuffle=True)
testLoader = torch.utils.data.DataLoader(dataset=testData, batch_size=batch_size, shuffle=False)

trainData.__len__()

model = models.resnet152(pretrained=False) 
model.fc = torch.nn.Linear(2048, 62) # full connected
model = model.cuda() 
criterion = torch.nn.CrossEntropyLoss() 
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

import time
from torch.autograd import Variable

train_loss = []
valid_loss = []
accuracy = []

def evaluate():
    model.eval()
    corrects = eval_loss = 0
    accs = []
    for image, label in testLoader:
        image = Variable(image.cuda()) #.cuda()
        label = Variable(label.cuda()) #.cuda()
        pred = model(image)
        loss = criterion(pred, label)
         
        eval_loss += loss.item()
        #acc = accuracy_score(label,pred)
        acc = torch.sum(torch.eq(pred.argmax(1),label))/len(pred.argmax(1))*100.0
        accs.append(acc)
    return eval_loss/float(len(testLoader)), corrects, sum(accs)/len(accs), len(testLoader)


def train():
    model.train()
    total_loss = 0
    for image, label in trainLoader:
        image = Variable(image.cuda()) #.cuda()
        label = Variable(label.cuda()) #.cuda()
        optimizer.zero_grad()

        target = model(image)
        loss = criterion(target, label)
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
    return total_loss/float(len(trainLoader))


best_acc = None
total_start_time = time.time()



try:
    print('-' * 90)
    for epoch in range(1, epoch+1):
        epoch_start_time = time.time()
        loss = train()
        train_loss.append(loss*1000.)

        print('| start of epoch {:3d} | time: {:2.2f}s | loss {:5.6f}'.format(epoch,
                                                                              time.time() - epoch_start_time,
                                                                              loss))
        evaluate_start_time = time.time()
        loss, corrects, acc, size = evaluate()
        valid_loss.append(loss*1000.)
        accuracy.append(acc)

        print('-' * 10)
        print((time.time() - evaluate_start_time)/400)
        print('| end of epoch {:3d} | time: {:2.2f}s | loss {:.4f} | accuracy {}%({}/{})'.format(epoch,
                                                                                                 time.time() - epoch_start_time,
                                                                                                 loss,
                                                                                                 acc,
                                                                                                 corrects,
                                                                                                 size))
        print('-' * 10)

    best_acc = max(accuracy)
    print("*" * 20, "\nBest Accuracy: ", best_acc)
except KeyboardInterrupt:
    print("-"*90)
    print("Exiting from training early | cost time: {:5.2f}min".format((time.time() - total_start_time)/60.0))

def load_images_from_folder_test(folder):
    images = []
    labels = []
    dim = (200,200)
    for filename in os.listdir(folder):
        if filename[-5] != "0" and filename[-6] != "0":
          continue
        img = cv.imread(os.path.join(folder,filename))
        if img is None:
          continue
        resized_img = cv.copyMakeBorder(img,80,80,0,0,cv.BORDER_CONSTANT,value=[255,255,255])
        lbl = filename[3:6]
        final_img = cv.resize(resized_img,dim,interpolation=cv.INTER_AREA)
        
        if final_img is not None:
            if lbl is not None:
                images.append(final_img)
                labels.append(lbl)
    
    return images, labels

